{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Programming - Assignment 3\n",
    "## Combining geographical numerical and textual data\n",
    "\n",
    "In this assignment you will combine weather and geonames data to find Europe's windiest cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a terminal and issue the following commands:\n",
    "\n",
    "`$ conda install basemap\n",
    "$ pip install wget\n",
    "`\n",
    "\n",
    "Accept all to install the extra packages required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import wget\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment you will need to download the following 3 files. The first one is ~343MB.\n",
    "\n",
    "`http://iit.demokritos.gr/~iaklampanos/assign3_data.npz\n",
    "http://iit.demokritos.gr/~iaklampanos/lat.npy\n",
    "http://iit.demokritos.gr/~iaklampanos/lon.npy\n",
    "http://download.geonames.org/export/dump/cities5000.zip`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1) Write a generic function to download a file from the Web (given a URL), if it is not already present locally. The function should be parameterisable w.r.t. the local directory to be used, the default being the current working directory (`./`). Use this function to assign values to variables `data_filename`, `lat_filename` and `lon_filename`. [2 marks]**\n",
    "\n",
    "*Hint: Use the wget package.*\n",
    "\n",
    "*Hint: When developing use the smaller `lat.npy` or `lon.npy`.*\n",
    "\n",
    "*Optional: Implement a function to allow wget to display the download progress in %. Try to find your way using `help(wget)` and by looking up the source code of wget online.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./assign3_data_v2.npz\n",
      "./lat.npy\n",
      "./lon.npy\n",
      "./cities5000.zip\n"
     ]
    }
   ],
   "source": [
    "def fetch_data(web_file, local_dir='.'):\n",
    "    \"\"\"Download the `web_file`, assuming it is a web resource into the local_dir. \n",
    "    If a file with the same filename already exists in the local directory, do not \n",
    "    download it but return its path instead.\n",
    "    Arguments:\n",
    "        web_file: a web resource identifiable by a url (str)\n",
    "        local_dir: a local directory to download the web_file into (str)\n",
    "    Return: The local path to the file (str)\n",
    "    \"\"\"\n",
    "    print local_dir+'/'+wget.detect_filename(web_file)\n",
    "    if os.path.exists(local_dir+'/'+wget.detect_filename(web_file)):\n",
    "        fp = open(wget.detect_filename(web_file))\n",
    "    else:\n",
    "        fp = wget.download(web_file)\n",
    "    return fp\n",
    "data_filename = fetch_data('http://iit.demokritos.gr/~iaklampanos/assign3_data_v2.npz') or 'assign3_data_v2.npz'\n",
    "lat_filename = fetch_data('http://iit.demokritos.gr/~iaklampanos/lat.npy') or 'lat.npy'\n",
    "lon_filename = fetch_data('http://iit.demokritos.gr/~iaklampanos/lon.npy') or 'lon.npy'\n",
    "cities_filename = fetch_data('http://download.geonames.org/export/dump/cities5000.zip') or 'cities5000.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three pieces of data you have downloaded are all numpy arrays which you can deserialise using `np.load`, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load(data_filename)['c137']\n",
    "lat = np.load(lat_filename)\n",
    "lon = np.load(lon_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geonames data (`cities5000.zip`) contains a text file (`cities5000.txt`) of tab-separated values. The description of this data is at http://download.geonames.org/export/dump/readme.txt. It lists the geographical locations and names of the cities with a population > 5000. \n",
    "\n",
    "**Unzip `cities5000.zip` to obtain `cities5000.txt`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (2) In this exercise we will need to extract the fields geonamesid, name, asciiname, \n",
    "latitude, longitude, contry code, population, elevation, dem and time zone (10 in total). Write a (*very* basic) class providing a human-readable enumeration to the fields above, corresponding to the format of the `cities5000.txt` file. [2 marks] **\n",
    "\n",
    "*Hint: e.g. for the field time zone, which is the 17th field in the file, we want to write F.TZ instead of 17. This will make our code more readable and more maintainable (e.g. in case the format changes in the future).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class F(object):\n",
    "    geonamesid = 0\n",
    "    name = 1\n",
    "    asciiname = 2\n",
    "    latitude = 4\n",
    "    longtitude = 5\n",
    "    country_code = 8\n",
    "    population = 14\n",
    "    elevation = 15\n",
    "    dem = 16\n",
    "    timezone=17\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print F.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** (3) Write a function to read cities5000.txt into a Python list, retaining the fields geonamesid, name, asciiname, latitude, longitude, contry code, population, elevation, dem and time zone. Use the class you defined above. [2 marks] **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cities(filename='cities5000.txt'):\n",
    "    \"\"\"Parse cities5000.txt and return a list containing a subset of its fields.\"\"\"\n",
    "    cities =[]\n",
    "    csv.field_size_limit(sys.maxsize)\n",
    "    with open(filename,'r') as f:\n",
    "        reader=csv.reader(f,delimiter='\\t')\n",
    "        for x in reader:\n",
    "            cities.append(x)\n",
    "    return cities\n",
    "cities = load_cities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4) Write a function that given a list of cities in the format above it selects cities based on their latitude and longitude, and minimum population. We want all cities within two pairs of (lat,long), with a population >= `population`. Use your function to get all european cities (coordinates provided below) with a population >= 100000 [2 marks] **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def latlong_filter(lat1, lon1, lat2, lon2, population=5000, cities=cities):\n",
    "    \"\"\"Return a sublist of the geonames cities from a northwestern point (`lat1`, `lon1`) \n",
    "       to a southeastern point (`lat2`, `lon2`) and with a minimum population of `population`\n",
    "    \"\"\"\n",
    "    filtered_cities=[]\n",
    "    for c in cities:\n",
    "        if float(c[F.latitude])>= LAT2 and float(c[F.latitude])<= LAT1 and float(c[F.longtitude])>= LON1 and float(c[F.longtitude])<= LON2:\n",
    "            if int(c[F.population])>population:\n",
    "                filtered_cities.append(c)\n",
    "    return filtered_cities\n",
    "\n",
    "LAT1 = 58.070942\n",
    "LON1 = -9.493621\n",
    "LAT2 = 34.103214\n",
    "LON2 = 29.686365\n",
    "european_cities = latlong_filter(LAT1, LON1, LAT2, LON2, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646\n"
     ]
    }
   ],
   "source": [
    "print len(european_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the `data` variable... `data` has been previously used in a classification experiment and has a complicated structure. We will use only part of it. Each row has 5 data fields: \n",
    "* [0] a human-readable name\n",
    "* [1] an id\n",
    "* [2] a date & time\n",
    "* [3] a 501x501 shape\n",
    "* [4] a 3x3x64x64 shape\n",
    "\n",
    "For our exercise we will use fields 2, the datetime, and 4. 4 corresponds to weather snapshots averaged over 78hr periods (3 days and 6hrs). Datetimes and weathers repeat over 2-year periods. We need to extract the datetimes and their corresponding weathers over a 2-year period, ignoring the rest. This corresponds to 224 records (rows)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5) Complete the function below, which should return a *copy* of the first 224 rows of `data` retaining only datetimes and weather. [2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_time_weather(data=data, rows=224):\n",
    "    pass\n",
    "times_weathers = extract_time_weather()\n",
    "# assert(times_weathers[0,1][0,0].shape == (64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather component of our data has a shape 3, 3, 64, 64. This corresponds to 3 variables (west-east wind component, south-north wind component, geopotential height), estimated at 3 pressure levels (500, 700, 900 hPa) respectively. The values are provided on a coarse 64x64 grid covering Europe.\n",
    "\n",
    "We will use wind information and our cities to find the windiest European cities per year season. But first we need to be able to find the cell, in the 64x64 image, which contains a location given a latitude, longitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(6) Complete the function below to convert a latitude, longitude pair into a pair of integers corresponding to the geographical point's coordinates in the 64x64 space. [2 marks]**\n",
    "\n",
    "*Hint: `convert_to_xy(latitude, longitude) -> x(0-63), y(0, 63)`*\n",
    "\n",
    "*Hint: use the `lon` and `lat` arrays defined above. Find the indexes of the input cell that is the closest to the arguments. Use the **`haversine()`** distance function provided below.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "    (https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas)\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "def convert_to_xy(latitude, longitude):\n",
    "    \"\"\"Map the coordinate provided (`latitude`, `longitude`) onto the weather 64x64 grid.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(7) Calculate the wind magnitude and append it into our wind data array. This array must have the same shape as the u- and v-wind component arrays [2] **\n",
    "\n",
    "*Hint: The magnitudes should have a shape of 3x64x64, i.e. each wind magnitude array (64x64) should correspond to a different pressure level (3 levels in total).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_weathers_mags = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(8) Calculate the average wind magnitude per season - quarters. Remember that our overall data cover 2 years [2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "magnitude_averages = None  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(9) Using the list of `european_cities` you calculated above, find the 10 windiest cities - i.e. the cities which are located in the cell with the highest magnitude - per season. Make sure you retain their indexes in `european_citites`, or that you also store their geolocation. Take into account only the 900hPa pressure level. [2 marks]**\n",
    "\n",
    "*Hint: You may want to create a function to avoid repeating code. You will also need to use the function `convert_to_xy` you created above*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_cities = None\n",
    "q2_cities = None\n",
    "q3_cities = None\n",
    "q4_cities = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(10) The function below displays a 64x64 data array onto a map. Change it so that it also displays a list of points - you will use this functionality to display city locations. Use your new function to display wind magnitude average and the 10 windiest cities per season. [2 marks]**\n",
    "\n",
    "*Hint: You will need to create 4 maps, one per season.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8, 8), dpi= 80)\n",
    "def display_on_map(data, title=None, lat=lat, lon=lon):\n",
    "    im = plt.imread('map-pin.png')\n",
    "\n",
    "    m = Basemap(width=3800E3, height=3800E3,\n",
    "                resolution='l', projection='lcc', lat_0 = 50, \n",
    "                lon_0 = 10, lat_ts = 40, k_0=1.0)\n",
    "    m.drawcoastlines(linewidth=1.0, color='#444444')\n",
    "    m.drawcountries(linewidth=1.0, color='#444444')\n",
    "    m.drawmapboundary(linewidth=1.0, color='#000000')\n",
    "    x, y = m(lon, lat)\n",
    "    try:\n",
    "        pass\n",
    "        cs = m.contour(x, y, data, linewidths=1.0, colors='k')\n",
    "    except:\n",
    "        pass\n",
    "    pcl = m.pcolor(x, y, np.squeeze(data))\n",
    "    cbar = m.colorbar(pcl, location='bottom', pad='2%')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()    \n",
    "display_on_map(data[0,4][0,0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
